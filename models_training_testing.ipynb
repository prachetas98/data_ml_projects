{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "## NAME: PRACHETAS DESHPANDE\n",
    "## DATA ANALYSIS PROJECT\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            user_id\n",
      "count   12000.00000\n",
      "mean   105999.50000\n",
      "std      3464.24595\n",
      "min    100000.00000\n",
      "25%    102999.75000\n",
      "50%    105999.50000\n",
      "75%    108999.25000\n",
      "max    111999.00000\n",
      "        product_id  number_of_reviews  avg_review_score\n",
      "count  1000.000000       1.000000e+03       1000.000000\n",
      "mean   1499.500000       1.157725e+05          2.660656\n",
      "std     288.819436       5.028997e+05          1.741875\n",
      "min    1000.000000       6.600000e+01         -1.000000\n",
      "25%    1249.750000       2.570000e+02          1.428969\n",
      "50%    1499.500000       4.710000e+02          2.769397\n",
      "75%    1749.250000       7.042500e+02          4.180860\n",
      "max    1999.000000       2.307390e+06          5.000000\n",
      "             user_id    product_id\n",
      "count   35990.000000  35990.000000\n",
      "mean   106017.080161   1500.232898\n",
      "std      3483.480090    288.101984\n",
      "min    100001.000000   1000.000000\n",
      "25%    102976.500000   1250.000000\n",
      "50%    106060.000000   1503.000000\n",
      "75%    109049.000000   1749.000000\n",
      "max    111999.000000   1999.000000\n"
     ]
    }
   ],
   "source": [
    "## Read all the necessary files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "user_features_df = pd.read_csv(\"user_features.csv\")\n",
    "product_features_df = pd.read_csv(\"product_features.csv\")\n",
    "click_history_df = pd.read_csv(\"click_history.csv\")\n",
    "print(user_features_df.describe())\n",
    "print(product_features_df.describe())\n",
    "print(click_history_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id number_of_clicks_before  ordered_before  product_id  clicked  \\\n",
      "0       104939                       2            True        1212    False   \n",
      "1       101992                       1            True        1212    False   \n",
      "2       110175                       0            True        1212     True   \n",
      "3       111017                       1           False        1212    False   \n",
      "4       103186                       0           False        1212    False   \n",
      "...        ...                     ...             ...         ...      ...   \n",
      "26121   102329                       4            True        1287    False   \n",
      "26122   100121                       0           False        1287     True   \n",
      "26123   106853                       0            True        1287     True   \n",
      "26124   109908                       0            True        1287     True   \n",
      "26125   104387                       2            True        1287     True   \n",
      "\n",
      "       on_sale  number_of_reviews  avg_review_score  \n",
      "0         True                789          1.461363  \n",
      "1         True                789          1.461363  \n",
      "2         True                789          1.461363  \n",
      "3         True                789          1.461363  \n",
      "4         True                789          1.461363  \n",
      "...        ...                ...               ...  \n",
      "26121     True                557          2.986042  \n",
      "26122     True                557          2.986042  \n",
      "26123     True                557          2.986042  \n",
      "26124     True                557          2.986042  \n",
      "26125     True                557          2.986042  \n",
      "\n",
      "[26126 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: In user_features.csv there are some places where the values are empty. I am going to fill these empty values ith 0s\n",
    "# About 10% of the data had records where one of the columns was empty\n",
    "user_features_df=user_features_df.fillna(0)\n",
    "\n",
    "# Step 2: In user_features.csv there is a column 'number_of_clicks_before' where the values are 6+ which are not proper integers. \n",
    "# Thus I'm assuming that these values are outliers and as a result I'm dropping those records from the dataframe\n",
    "# About 25% of the data had records where of the columns had +6 as the number_of_clicks_before\n",
    "user_features_df = user_features_df.drop(user_features_df[user_features_df['number_of_clicks_before'] == '6+'].index)\n",
    "\n",
    "# Step 3: In product_features.csv file there are some records where the number of reviews are above 20000 while most other products have \n",
    "# the total number of reviews between 100 and 1000. These records where the number of reviews are inordinatily high are outliers and would end up rpoducing inacuurate results by the ML models\n",
    "# Therefore, I am dropping those records where the number_of_reviews exceed 1000\n",
    "# About 10% of the records had the number of reviews beyond 1000\n",
    "product_features_df = product_features_df.drop(product_features_df[product_features_df['number_of_reviews'] > 1000].index)\n",
    "product_features_df = product_features_df.drop(product_features_df[product_features_df['avg_review_score'] < 0].index)\n",
    "\n",
    "# Step 4: The fourth step is to merge all the dataframe based on their user_id and product_id\n",
    "final_df = pd.merge(user_features_df, click_history_df, on='user_id').merge(product_features_df, on='product_id')\n",
    "\n",
    "# Step 5: The last step os to drop any columns that are not required for predictions to find the number of clicks. In this case personal interests and category are not relevant to predict the clicks\n",
    "final_df.drop(['personal_interests','category'],axis=1,inplace=True)\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting data into train and test sets\n",
    "# The code below is splitting the data into train and test data. The train and test data have been split into a ratio of 0.7:0.3 as requested\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "X = final_df.iloc[ : , final_df.columns != 'clicked']\n",
    "y = final_df.clicked\n",
    "X_train, X_test,y_train, y_test = train_test_split(X,y,test_size=0.30,shuffle=True,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is :0.6645828017351365\n",
      "precision score is :0.0\n",
      "F1 score is :0.0\n",
      "recall score is :0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      1.00      0.80      5209\n",
      "        True       0.00      0.00      0.00      2629\n",
      "\n",
      "    accuracy                           0.66      7838\n",
      "   macro avg       0.33      0.50      0.40      7838\n",
      "weighted avg       0.44      0.66      0.53      7838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## MODEL 1: LOGISTIC REGRESSION\n",
    "# This code is using the logistic regresssion model and the train data and test data that was derived from the previous code and determining how well the model performs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "lr = LogisticRegression(random_state=1)\n",
    "lr.fit(X_train,y_train)\n",
    "l_train_pred = lr.predict(X_train)\n",
    "l_test_pred = lr.predict(X_test)\n",
    "print(\"Accuracy score is :\" + str(accuracy_score(y_test,l_test_pred)))\n",
    "print(\"precision score is :\" + str(precision_score(y_test,l_test_pred,zero_division=0)))\n",
    "print(\"F1 score is :\" + str(f1_score(y_test,l_test_pred,zero_division=0)))\n",
    "print(\"recall score is :\" + str(recall_score(y_test,l_test_pred,zero_division=0)))\n",
    "print(sklearn.metrics.classification_report(y_test,l_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is :0.7217402398571064\n",
      "precision score is :0.6408805031446541\n",
      "F1 score is :0.48305285612704435\n",
      "recall score is :0.38759984785089385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      0.89      0.81      5209\n",
      "        True       0.64      0.39      0.48      2629\n",
      "\n",
      "    accuracy                           0.72      7838\n",
      "   macro avg       0.69      0.64      0.65      7838\n",
      "weighted avg       0.71      0.72      0.70      7838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## MODEL 2: GAUSSIAN NB\n",
    "# This code is using the gaussian nb model and the train data and test data that was derived from the previous code and determining how well the model performs\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train,y_train)\n",
    "nb_train_pred = nb.predict(X_train)\n",
    "nb_test_pred = nb.predict(X_test)\n",
    "print(\"Accuracy score is :\" + str(accuracy_score(y_test,nb_test_pred)))\n",
    "print(\"precision score is :\" + str(precision_score(y_test,nb_test_pred)))\n",
    "print(\"F1 score is :\" + str(f1_score(y_test,nb_test_pred)))\n",
    "print(\"recall score is :\" + str(recall_score(y_test,nb_test_pred)))\n",
    "print(sklearn.metrics.classification_report(y_test,nb_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.7438121969890278\n",
      "precision score is: 0.6253532498990715\n",
      "F1 score is: 0.6067371719545632\n",
      "recall score is: 0.5891974134651959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.82      0.81      5209\n",
      "        True       0.63      0.59      0.61      2629\n",
      "\n",
      "    accuracy                           0.74      7838\n",
      "   macro avg       0.71      0.71      0.71      7838\n",
      "weighted avg       0.74      0.74      0.74      7838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## MODEL 3: DECISION TREE\n",
    "# This code is using the decision tree model and the train data and test data that was derived from the previous code to determining how well the model performs\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "DT = tree.DecisionTreeClassifier(max_depth=10,min_samples_split=5,random_state=1)\n",
    "DT.fit(X_train,y_train)\n",
    "dt_train_pred = DT.predict(X_train)\n",
    "dt_test_pred = DT.predict(X_test)\n",
    "print(\"Accuracy score is: \" + str(accuracy_score(y_test,dt_test_pred)))\n",
    "print(\"precision score is: \" + str(precision_score(y_test,dt_test_pred)))\n",
    "print(\"F1 score is: \" + str(f1_score(y_test,dt_test_pred)))\n",
    "print(\"recall score is: \" + str(recall_score(y_test,dt_test_pred)))\n",
    "print(sklearn.metrics.classification_report(y_test,dt_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is :0.7612911457004338\n",
      "precision score is :0.5781666032712058\n",
      "F1 score is :0.6190185298309918\n",
      "recall score is :0.6660823838737949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.85      0.83      5209\n",
      "        True       0.67      0.58      0.62      2629\n",
      "\n",
      "    accuracy                           0.76      7838\n",
      "   macro avg       0.73      0.72      0.72      7838\n",
      "weighted avg       0.76      0.76      0.76      7838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## MODEL 4: NEURAL NETWORKING\n",
    "# This code is using the neural network model and the train data and test data that was derived from the previous code to determining how well the model performs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "scalar = MinMaxScaler()\n",
    "X_train_scaled = scalar.fit_transform(X_train)\n",
    "X_test_scaled = scalar.transform(X_test)\n",
    "NN= MLPClassifier(solver=\"lbfgs\",alpha=1e-5,hidden_layer_sizes=(10,4),random_state=1)\n",
    "NN.fit(X_train_scaled,y_train)\n",
    "NN_pred = NN.predict(X_test_scaled)\n",
    "print(\"Accuracy score is :\" + str(accuracy_score(NN_pred,y_test)))\n",
    "print(\"precision score is :\" + str(precision_score(NN_pred,y_test)))\n",
    "print(\"F1 score is :\" + str(f1_score(NN_pred,y_test)))\n",
    "print(\"recall score is :\" + str(recall_score(NN_pred,y_test)))\n",
    "print(sklearn.metrics.classification_report(y_test,NN_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of linear kernel is: 0.6593518754784384\n",
      "precision score is :0.14035087719298245\n",
      "F1 score is :0.005956813104988831\n",
      "recall score is :0.0030429821224800305\n"
     ]
    }
   ],
   "source": [
    "## MODEL 5: SUPPORT VECTOR MACHINES - LINEAR\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "svm_linear = svm.SVC(kernel='linear')\n",
    "svm_linear.fit(X_train,y_train)\n",
    "svm_linear_pred = svm_linear.predict(X_test)\n",
    "print(\"The accuracy score of linear kernel is: \" + str(metrics.accuracy_score(y_test,svm_linear_pred)))\n",
    "print(\"precision score is :\" + str(precision_score(y_test,svm_linear_pred)))\n",
    "print(\"F1 score is :\" + str(f1_score(y_test,svm_linear_pred)))\n",
    "print(\"recall score is :\" + str(recall_score(y_test,svm_linear_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of rbf kernel is: 0.6645828017351365\n",
      "precision score is :0.0\n",
      "F1 score is :0.0\n",
      "recall score is :0.0\n"
     ]
    }
   ],
   "source": [
    "## MODEL 6: SUPPORT VECTOR MACHINES - RBF\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "svm_rbf = svm.SVC(kernel='rbf')\n",
    "svm_rbf.fit(X_train,y_train)\n",
    "svm_rbf_pred = svm_rbf.predict(X_test)\n",
    "print(\"The accuracy score of rbf kernel is: \" + str(metrics.accuracy_score(y_test,svm_rbf_pred)))\n",
    "print(\"precision score is :\" + str(precision_score(y_test,svm_rbf_pred)))\n",
    "print(\"F1 score is :\" + str(f1_score(y_test,svm_rbf_pred)))\n",
    "print(\"recall score is :\" + str(recall_score(y_test,svm_rbf_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of poly kernel is: 0.6645828017351365\n",
      "precision score is :0.0\n",
      "F1 score is :0.0\n",
      "recall score is :0.0\n"
     ]
    }
   ],
   "source": [
    "## MODEL 7: SUPPORT VECTOR MACHINES - poly\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "svm_poly = svm.SVC(kernel='poly')\n",
    "svm_poly.fit(X_train,y_train)\n",
    "svm_poly_pred = svm_poly.predict(X_test)\n",
    "print(\"The accuracy score of poly kernel is: \" + str(metrics.accuracy_score(y_test,svm_poly_pred)))\n",
    "print(\"precision score is :\" + str(precision_score(y_test,svm_poly_pred)))\n",
    "print(\"F1 score is :\" + str(f1_score(y_test,svm_poly_pred)))\n",
    "print(\"recall score is :\" + str(recall_score(y_test,svm_poly_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.7241643276346007\n",
      "precision score is :0.5424115633320654\n",
      "F1 score is :0.5688073394495413\n",
      "recall score is :0.5979035639412998\n"
     ]
    }
   ],
   "source": [
    "## MODEL 8: RANDOM FOREST CLASSIFIER\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# create a random forest classifier\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# define a range of values for n_estimators to try\n",
    "n_estimators_values = [100, 200, 300, 400, 500, 600]\n",
    "\n",
    "# perform 5-fold cross-validation for each value of n_estimators\n",
    "cv_scores = []\n",
    "for n_estimator in n_estimators_values:\n",
    "    rf.set_params(n_estimators=n_estimator)\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=10)\n",
    "    cv_scores.append(np.mean(scores))\n",
    "\n",
    "# find the best value of n_estimators\n",
    "best_n_estimators = n_estimators_values[np.argmax(cv_scores)]\n",
    "\n",
    "# train the final model using the best value of n_estimators\n",
    "rf.set_params(n_estimators=best_n_estimators)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "print(\"The accuracy score is: \" + str(metrics.accuracy_score(rf_pred,y_test)))\n",
    "print(\"precision score is :\" + str(precision_score(rf_pred,y_test)))\n",
    "print(\"F1 score is :\" + str(f1_score(rf_pred,y_test)))\n",
    "print(\"recall score is :\" + str(recall_score(rf_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.7633324827762185\n",
      "precision score is :0.5793077215671358\n",
      "F1 score is :0.6215058151397674\n",
      "recall score is :0.6703345070422535\n"
     ]
    }
   ],
   "source": [
    "## MODEL 9: ADA BOOST CLASSIFIER\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# create a random forest classifier\n",
    "AD = AdaBoostClassifier(random_state=0)\n",
    "\n",
    "# define a range of values for n_estimators to try\n",
    "n_estimators_values = [100, 200, 300, 400, 500, 600]\n",
    "\n",
    "# perform 5-fold cross-validation for each value of n_estimators\n",
    "cv_scores = []\n",
    "for n_estimators in n_estimators_values:\n",
    "    AD.set_params(n_estimators=n_estimators,learning_rate=0.05)\n",
    "    scores = cross_val_score(AD, X_train, y_train)\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# find the best value of n_estimators\n",
    "best_n_estimators = n_estimators_values[np.argmax(cv_scores)]\n",
    "# train the final model using the best value of n_estimators\n",
    "AD.set_params(n_estimators=best_n_estimators)\n",
    "AD.fit(X_train, y_train)\n",
    "AD_pred = AD.predict(X_test)\n",
    "print(\"The accuracy score is: \" + str(metrics.accuracy_score(AD_pred,y_test)))\n",
    "print(\"precision score is :\" + str(precision_score(AD_pred,y_test)))\n",
    "print(\"F1 score is :\" + str(f1_score(AD_pred,y_test)))\n",
    "print(\"recall score is :\" + str(recall_score(AD_pred,y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
